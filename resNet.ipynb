{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc68bda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-31 17:28:23.202095: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "try:\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "import tensorflow as tf\n",
    "# import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.layers import Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0ea167b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras import callbacks\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "714a67e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# !wget https://cernbox.cern.ch/remote.php/dav/public-files/AtBT8y4MiQYFcgc/SinglePhotonPt50_IMGCROPS_n249k_RHv1.hdf5\n",
    "# !wget https://cernbox.cern.ch/remote.php/dav/public-files/FbXw3V4XNyYB3oA/SingleElectronPt50_IMGCROPS_n249k_RHv1.hdf5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee37d09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "photon_dataset = h5py.File('SinglePhotonPt50_IMGCROPS_n249k_RHv1.hdf5', 'r')\n",
    "electron_dataset = h5py.File('SingleElectronPt50_IMGCROPS_n249k_RHv1.hdf5', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83f3456c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/laughtale/anaconda3/lib/python3.11/site-packages/torch/cuda/__init__.py:141: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb575a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building class for Residual Identity Block using class API of keras\n",
    "class IdentityBlock(tf.keras.Model):\n",
    "  def __init__(self, filters, kernel_size):\n",
    "    super(IdentityBlock, self).__init__(name=\"\")\n",
    "    self.conv1 = tf.keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, padding='same')\n",
    "    self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "    self.act = tf.keras.layers.Activation('relu')\n",
    "    self.conv2 = tf.keras.layers.Conv2D(filters = filters, kernel_size = kernel_size, padding='same')\n",
    "    self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "    self.add = tf.keras.layers.Add()\n",
    "\n",
    "  def call(self, input_tensor):\n",
    "    x = self.conv1(input_tensor)\n",
    "    x = self.bn1(x)\n",
    "    x = self.act(x)\n",
    "    x = self.conv2(x)\n",
    "    x = self.bn2(x)\n",
    "    x= self.act(x)\n",
    "    x = self.add([x, input_tensor])\n",
    "    x= self.act(x)\n",
    "    return x \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5c4ad5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now building the Resnet\n",
    "class Resnet(tf.keras.Model):\n",
    "  def __init__(self, num_classes):\n",
    "    super(Resnet, self).__init__()\n",
    "    self.conv = tf.keras.layers.Conv2D(64, 7, padding = 'same')\n",
    "    self.bn = tf.keras.layers.BatchNormalization()\n",
    "    self.act = tf.keras.layers.Activation('relu')\n",
    "    self.max_pool = tf.keras.layers.MaxPool2D(3,3)\n",
    "    self.id1 = IdentityBlock(64,3)\n",
    "    self.id2 = IdentityBlock(64,3)\n",
    "    self.global_pool = tf.keras.layers.GlobalAveragePooling2D()\n",
    "    self.classifier = tf.keras.layers.Dense(num_classes, activation = 'softmax')\n",
    "\n",
    "  def call(self, input_tensor):\n",
    "    x = self.conv(input_tensor)\n",
    "    x = self.bn(x)\n",
    "    x = self.act(x)\n",
    "    x = self.max_pool(x)\n",
    "    x = self.id1(x)\n",
    "    x = self.id2(x)\n",
    "    x = self.global_pool(x)\n",
    "    x = self.classifier(x)\n",
    "    return x\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f76c5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-31 17:28:44.344430: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "model = Resnet(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "291277e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_diagnostics(history):\n",
    "    plt.subplots(figsize = (7,7))\n",
    "    # plot loss\n",
    "    plt.subplot(211)\n",
    "    plt.title('Cross Entropy Loss')\n",
    "    plt.plot(history.history['loss'], color='blue', label='train')\n",
    "    plt.plot(history.history['val_loss'], color='orange', label='test')\n",
    "\n",
    "    # plot accuracy\n",
    "    plt.subplot(212)\n",
    "    plt.title('Classification Accuracy')\n",
    "    plt.plot(history.history['accuracy'], color='blue', label='train')\n",
    "    plt.plot(history.history['val_acc'], color='orange', label='test')\n",
    "    plt.show()\n",
    "    # save plot to file\n",
    "    filename = sys.argv[0].split('/')[-1]\n",
    "    plt.savefig(filename + '_plot.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "671ff8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(photon_file, electron_file):\n",
    "    # Open photon and electron datasets\n",
    "#     photon_dataset = h5py.File(photon_file, 'r')\n",
    "#     electron_dataset = h5py.File(electron_file, 'r')\n",
    "    \n",
    "    # Concatenate images and labels from both datasets\n",
    "    X_photon = np.array(photon_dataset['X'])\n",
    "    y_photon = np.array(photon_dataset['y'])\n",
    "    X_electron = np.array(electron_dataset['X'])\n",
    "    y_electron = np.array(electron_dataset['y'])\n",
    "    \n",
    "    X = np.concatenate([X_photon, X_electron])\n",
    "    y = np.concatenate([y_photon, y_electron])\n",
    "    \n",
    "    # Split data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=23)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304327e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = preprocess_dataset('SinglePhotonPt50_IMGCROPS_n249k_RHv1.hdf5', 'SingleElectronPt50_IMGCROPS_n249k_RHv1.hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d312c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_split(X_test, y_test, valid_X, valid_Y, v_split):\n",
    "\n",
    "    index_of_validation = int(v_split * len(X_test))\n",
    "    valid_X.extend(X_test[-index_of_validation:])\n",
    "    valid_Y.extend(y_test[-index_of_validation:])\n",
    "    X_test = X_test[:-index_of_validation]\n",
    "    y_test = y_test[:-index_of_validation]\n",
    "    return X_test, y_test, np.asarray(valid_X), np.asarray(valid_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a002036a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a374ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model():\n",
    "#     X_train, y_train, X_test, y_test = load_dataset()\n",
    "    X_train, X_test, y_train, y_test = preprocess_dataset('SinglePhotonPt50_IMGCROPS_n249k_RHv1.hdf5', 'SingleElectronPt50_IMGCROPS_n249k_RHv1.hdf5')\n",
    "\n",
    "\n",
    "    #get validation set \n",
    "    valid_X = []\n",
    "    valid_Y = []\n",
    "    X_test, y_test, validX, validY = validation_split(X_test, y_test, valid_X, valid_Y,v_split=0.5)\n",
    "\n",
    "    model =model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "#     model_VGG()\n",
    "    \n",
    "\n",
    "    ##create data generator \n",
    "    #datagen = ImageDataGenerator(width_shift_range = 0.1, height_shift_range = 0.1, horizontal_flip = True)\n",
    "    #iterator \n",
    "    #train = datagen.flow(X_train, y_train, batch_size = 64)\n",
    "    \n",
    "\n",
    "    #checkpoint for early stopping \n",
    "    checkpoint = ModelCheckpoint(\"vgg16_1.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "    early = EarlyStopping(monitor='val_acc', min_delta=0, patience=3, verbose=1, mode='auto')\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1.e-6)\n",
    "\n",
    "    # fit model\n",
    "    steps = int(X_train.shape[0]/ 64)\n",
    "    history = model.fit(X_train, y_train,\n",
    "                        batch_size = 64, \n",
    "                        steps_per_epoch = steps, \n",
    "                        epochs=50, \n",
    "                        validation_data=(validX, validY),\n",
    "                        verbose=1, shuffle = True ,\n",
    "                        callbacks=[reduce_lr])\n",
    "    \n",
    "    #evaluate on validation dataset\n",
    "    score = model.evaluate(validX, validY , verbose=1)\n",
    "    print(f'Test loss: {score[0]} / Test accuracy: {score[1]}') \n",
    "    y_pred = model.predict(validX)\n",
    "    fpr, tpr, _ = roc_curve(validY, y_pred)\n",
    "    ROC = auc(fpr, tpr)\n",
    "    print('Validation ROC AUC: ',ROC)\n",
    "\n",
    "    #evaluate on test dataset\n",
    "    score = model.evaluate(X_test, y_test, verbose=1)\n",
    "    print(f'Test loss: {score[0]} / Test accuracy: {score[1]}') \n",
    "    y_pred = model.predict(X_test)\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "    ROC = auc(fpr, tpr)\n",
    "    print('Test ROC AUC: ',ROC)\n",
    "    #summarize_diagnostics(history)\n",
    "    return history\n",
    "\n",
    "def main():\n",
    "\ttest_model()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58840e7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
